{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stocks Rag\n",
    "\n",
    "Author: Orvin Bellamy (https://github.com/orvinbellamy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import libraries\n",
    "\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "from dotenv import load_dotenv\n",
    "import logging as log\n",
    "from filehandler import FileHandler\n",
    "from yfinancehandler import YFHandler\n",
    "from eventhandler import EventHandler, ThreadManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_run_status(client, thread_id: str, run_id: str, n_tries: int, wait_time):\n",
    "    \n",
    "    ## Wait until status is completed\n",
    "    for i in range(0, n_tries):\n",
    "\n",
    "        # Retrieve the latest run\n",
    "        run_retrieve = client.beta.threads.runs.retrieve(\n",
    "            thread_id=thread_id,\n",
    "            run_id=run_id\n",
    "        )\n",
    "\n",
    "        # Get the run status\n",
    "        run_status = run_retrieve.status\n",
    "\n",
    "        # Check run status\n",
    "        if run_status == 'completed':\n",
    "            print('Run is completed')\n",
    "            return f'Run is completed (run_id: {run_id}, thread_id {thread_id})'\n",
    "        elif run_status == 'in_progress':\n",
    "            print('Run is in progress')\n",
    "            pass\n",
    "        elif run_status == 'queued':\n",
    "            print('Run is queued')\n",
    "            pass\n",
    "        elif run_status == 'cancelling':\n",
    "            print('Run is cancelling')\n",
    "            pass\n",
    "        elif run_status == 'cancelled':\n",
    "            raise ValueError(f'Error: run is cancelled (run_id: {run_id}, thread_id {thread_id})')\n",
    "        elif run_status == 'failed':\n",
    "            raise ValueError(f'Error: run has failed (run_id: {run_id}, thread_id {thread_id})')\n",
    "        elif run_status == 'expired':\n",
    "            raise ValueError(f'Error: run has expired (run_id: {run_id}, thread_id {thread_id})')\n",
    "        elif run_status == 'requires_action':\n",
    "            print('Action is required')\n",
    "            return f'Action required (run_id: {run_id}, thread_id {thread_id})'\n",
    "\n",
    "        # Sleep to give time for the run to process\n",
    "        time.sleep(wait_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## configruation\n",
    "\n",
    "FILE_PATH = 'openai_upload_files/'\n",
    "OPENAI_DIC_FILE_NAME = 'openai_files.json'\n",
    "\n",
    "# Set constants for loops\n",
    "NUM_TRIES = 12\n",
    "TIME_SLEEP = 5 # in seconds\n",
    "\n",
    "# load_dotenv('config.env')\n",
    "# OPEN_API_KEY = os.getenv('OPEN_API_KEY')\n",
    "\n",
    "# List of JSON files\n",
    "# json_files = [('income_stmt', 'df_income_stmt_columns.json'), ('cashflow', 'df_cashflow_columns.json'), ('stocks', 'df_stocks_columns.json')]\n",
    "\n",
    "# Load schemas from JSON file\n",
    "with open('dataframe_schemas.json', 'r') as f:\n",
    "    schemas = json.load(f)\n",
    "\n",
    "with open('config/config.json', 'r') as f:\n",
    "    dic_config = json.load(f)\n",
    "    OPEN_API_KEY = dic_config['OPEN_API_KEY']\n",
    "    FIN_ANALYST_ID = dic_config['fin_analyst_assistant']\n",
    "\n",
    "# Initialize an empty list to store the stocks\n",
    "stocks_list = []\n",
    "\n",
    "# Open the text file in read mode\n",
    "with open('stocks.txt', 'r') as file:\n",
    "    # Read each line of the file\n",
    "    for line in file:\n",
    "        # Strip any leading or trailing whitespace and append the line to the list\n",
    "        stocks_list.append(line.strip())\n",
    "\n",
    "df_portfolio = pd.read_csv('config/portfolio.csv')\n",
    "\n",
    "list_portfolio = list(df_portfolio['ticker'].unique())\n",
    "\n",
    "with open(f'{FILE_PATH}{OPENAI_DIC_FILE_NAME}', 'r') as f:\n",
    "    dic_files = json.load(f)\n",
    "\n",
    "client = OpenAI(api_key=OPEN_API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stocks Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Documents\\Python Repo\\stock_rag\\yfinancehandler.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, df_plc], ignore_index=True)\n",
      "d:\\Documents\\Python Repo\\stock_rag\\yfinancehandler.py:34: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, df_plc], ignore_index=True)\n",
      "d:\\Documents\\Python Repo\\stock_rag\\yfinancehandler.py:48: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, df_plc], ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "stocks_list = ['MSFT', 'SHOP', 'AMD', 'NVDA', 'AAPL', 'OKTA', 'SHOP', 'AMAT', 'TTWO', 'SNOW', 'SOXX', 'BA', 'DOCN', 'MCD', 'LULU', 'CSCO', 'ORCL', 'AMZN', 'ASML']\n",
    "\n",
    "yf_handler = YFHandler(stock_list=stocks_list, schemas=schemas)\n",
    "\n",
    "df_stocks = yf_handler.import_stocks()\n",
    "df_cashflow = yf_handler.import_cashflow()\n",
    "df_income_stmt = yf_handler.import_income_stmt()\n",
    "\n",
    "# Write to CSV\n",
    "# Technically this will be done by the FileHandler but just to be safe\n",
    "df_stocks.to_csv('openai_upload_files/df_stocks.csv', index=False)\n",
    "df_cashflow.to_csv('openai_upload_files/df_cashflow.csv', index=False)\n",
    "df_income_stmt.to_csv('openai_upload_files/df_income_stmt.csv', index=False)\n",
    "\n",
    "file_stocks = FileHandler(\n",
    "    df=df_stocks,\n",
    "    dic_file=dic_files,\n",
    "    file_name='df_stocks.csv',\n",
    "    file_path=FILE_PATH,\n",
    "    client=client\n",
    ")\n",
    "\n",
    "file_cashflow = FileHandler(\n",
    "    df=df_cashflow,\n",
    "    dic_file=dic_files,\n",
    "    file_name='df_cashflow.csv',\n",
    "    file_path=FILE_PATH,\n",
    "    client=client\n",
    ")\n",
    "\n",
    "file_income_stmt = FileHandler(\n",
    "    df=df_income_stmt,\n",
    "    dic_file=dic_files,\n",
    "    file_name='df_income_stmt.csv',\n",
    "    file_path=FILE_PATH,\n",
    "    client=client\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file name: df_stocks.csv, file id: file-6l5H1TqYaKCtnCTJeiCNfSjA has been deleted\n",
      "file name: df_stocks.csv is uploaded, new file id: file-NcAYobSXtKGKAJMylEsaGF2v\n",
      "openai_upload_files/openai_files.json file has been updated\n",
      "file name: df_cashflow.csv, file id: file-6PfALiBYEIgDxzIAj6gtXLjC has been deleted\n",
      "file name: df_cashflow.csv is uploaded, new file id: file-Tm3qkLMs00Lop4LPDJKGKMmi\n",
      "openai_upload_files/openai_files.json file has been updated\n",
      "file name: df_income_stmt.csv, file id: file-M7S4zXPiQb8bsdww3M12lYut has been deleted\n",
      "file name: df_income_stmt.csv is uploaded, new file id: file-Z3eZzIA2VaImoSlLLJeGSY2O\n",
      "openai_upload_files/openai_files.json file has been updated\n"
     ]
    }
   ],
   "source": [
    "# Update files\n",
    "file_stocks.update_openai_file(dic_file=dic_files, dic_file_name=OPENAI_DIC_FILE_NAME, dic_file_path=FILE_PATH)\n",
    "file_cashflow.update_openai_file(dic_file=dic_files, dic_file_name=OPENAI_DIC_FILE_NAME, dic_file_path=FILE_PATH)\n",
    "file_income_stmt.update_openai_file(dic_file=dic_files, dic_file_name=OPENAI_DIC_FILE_NAME, dic_file_path=FILE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('config/assistants.json', 'r') as f:\n",
    "    dic_assistants= json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assistant id asst_I4lFSi5mtU5OYoeivxOc4piG\n",
    "\n",
    "assistant = client.beta.assistants.update(\n",
    "    assistant_id=dic_assistants['fin_analyst']['id'], \n",
    "    instructions=dic_assistants['fin_analyst']['instructions'],\n",
    "    model=dic_assistants['fin_analyst']['model'],\n",
    "    tools=dic_assistants['fin_analyst']['tools'],\n",
    "    tool_resources={\n",
    "        'code_interpreter': {\n",
    "            'file_ids': [file_stocks.file_id]\n",
    "        }\n",
    "    }\n",
    ")\n",
    "# file_stocks.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'0'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 32\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# # Set dictionary for tracking messages\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# dic_messages = {}\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# ) as stream:\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m#     stream.until_done()\u001b[39;00m\n\u001b[1;32m---> 32\u001b[0m \u001b[43mdic\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m0\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "\u001b[1;31mKeyError\u001b[0m: '0'"
     ]
    }
   ],
   "source": [
    "# # Set dictionary for tracking messages\n",
    "# dic_messages = {}\n",
    "\n",
    "# ## Create thread\n",
    "# thread = client.beta.threads.create(\n",
    "#     messages=[\n",
    "#         {\n",
    "#             'role': 'user',\n",
    "#             'content': 'Can you explain to me what the file I have attached is.',\n",
    "#             'attachments': [\n",
    "#                 {\n",
    "#                     'file_id': file_stocks.file_id,\n",
    "#                     'tools': [{'type': 'code_interpreter'}]\n",
    "#                 }\n",
    "#             ]\n",
    "#         }\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "# # Get thread id\n",
    "# thread_id = thread.id\n",
    "\n",
    "# # Record first message\n",
    "# dic_messages['0'] = get_last_message(client=client, thread_id=thread_id)\n",
    "\n",
    "with client.beta.threads.runs.stream(\n",
    "    thread_id=thread.id,\n",
    "    assistant_id=FIN_ANALYST_ID,\n",
    "    event_handler=EventHandler(),\n",
    ") as stream:\n",
    "    stream.until_done()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "assistant > code_interpreter\n",
      "\n",
      "import pandas as pd\n",
      "\n",
      "# Load and inspect the first few rows of the file\n",
      "file_path = '/mnt/data/file-NcAYobSXtKGKAJMylEsaGF2v'\n",
      "df = pd.read_excel(file_path)\n",
      "\n",
      "# Display the first few rows of the dataframe\n",
      "df.head()\n",
      "assistant > It seems that there is an issue with determining the format of the Excel file. Let's try specifying the engine explicitly to see if that helps. I will also load the first few rows of the file to check its content.# Retry reading the file with an explicit engine\n",
      "df = pd.read_excel(file_path, engine='openpyxl')\n",
      "\n",
      "# Display the first few rows of the dataframe\n",
      "df.head()\n",
      "assistant > It appears that the file is not in a valid Excel format or is corrupted, as it can't be read by typical Excel file readers. This could be due to several reasons; for example, the file might have a different format than expected or it could be corrupted.\n",
      "\n",
      "Let's inspect the other uploaded file to see if that one is also problematic or if it can be read successfully.# Load and inspect the first few rows of the second uploaded file\n",
      "file_path_2 = '/mnt/data/file-RFDn3ItudTsuyQwDM8zavKiM'\n",
      "df2 = pd.read_excel(file_path_2, engine='openpyxl')\n",
      "\n",
      "# Display the first few rows of the dataframe\n",
      "df2.head()\n",
      "assistant > Both of the uploaded files appear to have issues with being read as valid Excel files. This could indicate that they are either corrupted or not actually in Excel format despite having a \".xlsx\" extension.\n",
      "\n",
      "To proceed, could you please verify the contents of the files on your end? Ensure they are indeed in Excel format. If they are intended to be different types of files (e.g., CSV, text documents, etc.), please let me know or re-upload the correct files. Alternatively, you can also try opening them with Excel or a similar program to check if they are accessible."
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'message_id': 'msg_8GLQV8vCXX85ca1AiUwkpzEB',\n",
       " 'assistant_id': 'asst_Mqf9cO1sDTOd4UMYwcFfIQrA',\n",
       " 'created_at': 1722495443,\n",
       " 'file_ids': [],\n",
       " 'role': 'assistant',\n",
       " 'run_id': 'run_1w2TRxE4W1VmrsBX57tJbzUT',\n",
       " 'message_text': 'Both of the uploaded files appear to have issues with being read as valid Excel files. This could indicate that they are either corrupted or not actually in Excel format despite having a \".xlsx\" extension.\\n\\nTo proceed, could you please verify the contents of the files on your end? Ensure they are indeed in Excel format. If they are intended to be different types of files (e.g., CSV, text documents, etc.), please let me know or re-upload the correct files. Alternatively, you can also try opening them with Excel or a similar program to check if they are accessible.'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Create thread\n",
    "thread = client.beta.threads.create(\n",
    "    messages=[\n",
    "        {\n",
    "            'role': 'user',\n",
    "            'content': 'Can you explain to me what the file I have attached is.',\n",
    "            'attachments': [\n",
    "                {\n",
    "                    'file_id': file_stocks.file_id,\n",
    "                    'tools': [{'type': 'code_interpreter'}]\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Get thread id\n",
    "thread_id = thread.id\n",
    "\n",
    "# Set ThreadManager to easily track messages in a single thread\n",
    "thread_fin_analyst = ThreadManager(client=client, thread_id=thread_id)\n",
    "\n",
    "# # Run assistants\n",
    "# # Run should use stream now instaed of create\n",
    "# run = client.beta.threads.runs.create(\n",
    "#     thread_id = thread.id,\n",
    "#     assistant_id=FIN_ANALYST_ID\n",
    "# )\n",
    "\n",
    "# run_id = run.id\n",
    "\n",
    "# NUM_TRIES = 10\n",
    "# TIME_SLEEP = 5\n",
    "\n",
    "# check_run_status = check_run_status(client=client, thread_id=thread_id, run_id=run_id, wait_time=TIME_SLEEP, n_tries=NUM_TRIES)\n",
    "\n",
    "# # final step is to delete the thread\n",
    "# # client.beta.threads.delete(thread_id=THREAD_ID)\n",
    "\n",
    "with client.beta.threads.runs.stream(\n",
    "    thread_id=thread.id,\n",
    "    assistant_id=FIN_ANALYST_ID,\n",
    "    event_handler=EventHandler(),\n",
    ") as stream:\n",
    "    stream.until_done()\n",
    "\n",
    "thread_fin_analyst.get_last_message()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Thread' object has no attribute 'messages'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Set ThreadManager to easily track messages in a single thread\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mthread\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmessages\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# client.beta.threads.delete(thread_id=thread_id)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Orvin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pydantic\\main.py:828\u001b[0m, in \u001b[0;36mBaseModel.__getattr__\u001b[1;34m(self, item)\u001b[0m\n\u001b[0;32m    825\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getattribute__\u001b[39m(item)  \u001b[38;5;66;03m# Raises AttributeError if appropriate\u001b[39;00m\n\u001b[0;32m    826\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    827\u001b[0m     \u001b[38;5;66;03m# this is the current error\u001b[39;00m\n\u001b[1;32m--> 828\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mitem\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Thread' object has no attribute 'messages'"
     ]
    }
   ],
   "source": [
    "# Set ThreadManager to easily track messages in a single thread\n",
    "thread\n",
    "# client.beta.threads.delete(thread_id=thread_id)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
